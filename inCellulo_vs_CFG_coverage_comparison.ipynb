{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c47a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "import pysam\n",
    "import csv\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import exists\n",
    "from Bio import SeqRecord\n",
    "import scipy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d557bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# written by Peter Culviner, PhD to enable command-line access through Jupyter\n",
    "def quickshell(command, print_output=True, output_path=None, return_output=False):\n",
    "    process_output = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout = process_output.stdout.decode('utf-8')\n",
    "    stderr = process_output.stderr.decode('utf-8')\n",
    "    output_string = f'STDOUT:\\n{stdout}\\nSTDERR:\\n{stderr}\\n'\n",
    "    if print_output:\n",
    "        print('$ ' + command)\n",
    "        print(output_string)\n",
    "    if output_path is not None:\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(output_string)\n",
    "    if return_output:\n",
    "        return stdout, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff47b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'inCellulo'\n",
    "genome_dir = f'{main_path}/genomes'\n",
    "\n",
    "fastqc_dir = f'{main_path}/fastqc'\n",
    "\n",
    "cortes_TSS_dir = f'{main_path}/cortes_TSS'\n",
    "cortes_TSS_raw_fastq = f'{cortes_TSS_dir}/fastq'\n",
    "cortes_TSS_processed_fastq = f'{cortes_TSS_dir}/processed_fastq'\n",
    "cortes_ribodetect = f'{cortes_TSS_dir}/ribodetect_fastq'\n",
    "\n",
    "arnvig_TTS_dir = f'{main_path}/arnvig_TTS'\n",
    "arnvig_TTS_raw_fastq = f'{arnvig_TTS_dir}/fastq'\n",
    "arnvig_TTS_processed_fastq = f'{arnvig_TTS_dir}/processed_fastq'\n",
    "arnvig_ribodetect = f'{arnvig_TTS_dir}/ribodetect_fastq'\n",
    "\n",
    "alignments = f'{main_path}/inCellulo_alignments'\n",
    "downsampled = f'{main_path}/downsampled_alignments'\n",
    "trimmed = f'{main_path}/trimmed_alignments'\n",
    "summarizeOverlaps = f'{main_path}/summarized_overlaps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir $fastqc_dir\n",
    "!mkdir $cortes_TSS_dir\n",
    "!mkdir $cortes_TSS_raw_fastq\n",
    "!mkdir $cortes_TSS_processed_fastq\n",
    "!mkdir $cortes_ribodetect\n",
    "!mkdir $arnvig_TTS_dir\n",
    "!mkdir $arnvig_TTS_raw_fastq\n",
    "!mkdir $arnvig_TTS_processed_fastq\n",
    "!mkdir $arnvig_ribodetect\n",
    "!mkdir $alignments\n",
    "!mkdir $downsampled\n",
    "!mkdir $trimmed\n",
    "!mkdir $summarizeOverlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_5end_path = '5enrich_CRP'\n",
    "CFG_3end_path = '3enrich_NusAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043a3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 18\n",
    "minimum_insert_length = 10\n",
    "quality_threshold = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed4505",
   "metadata": {},
   "source": [
    "# Fetch raw fastq files from ArrayExpress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4db7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accession_number_list_5end = ['ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR262/ERR262985/ERR262985.fastq.gz',\n",
    "                             'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR262/ERR262979/ERR262979.fastq.gz',\n",
    "                             'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR262/ERR262986/ERR262986.fastq.gz']\n",
    "\n",
    "for sample in accession_number_list_5end:\n",
    "    fetch_5end_command = f'wget -P {cortes_TSS_raw_fastq}/ {sample}'\n",
    "\n",
    "    fetch_5end_fastq = quickshell(fetch_5end_command, print_output = False, return_output = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c28251",
   "metadata": {},
   "outputs": [],
   "source": [
    "accession_number_list_3end = ['ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR973/008/ERR9735888/ERR9735888.fastq.gz',\n",
    "                             'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR973/009/ERR9735889/ERR9735889.fastq.gz',\n",
    "                             'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR973/000/ERR9735890/ERR9735890.fastq.gz']\n",
    "\n",
    "for sample in accession_number_list_3end:\n",
    "    fetch_3end_command = f'wget -P {arnvig_TTS_raw_fastq}/ {sample}'\n",
    "\n",
    "    fetch_3end_fastq = quickshell(fetch_3end_command, print_output = False, return_output = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5afba0",
   "metadata": {},
   "source": [
    "# Run fastqc to get an overview of Cortes and Arnvig fastq files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce723939",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_list = [f'{cortes_TSS_raw_fastq}/Exp_R1_TSS.fastq.gz',\n",
    "              f'{cortes_TSS_raw_fastq}/Exp_R2_TSS.fastq.gz',\n",
    "              f'{cortes_TSS_raw_fastq}/Exp_R3_TSS.fastq.gz',\n",
    "              f'{arnvig_TTS_raw_fastq}/termseq_expo_r1.fastq.gz',\n",
    "              f'{arnvig_TTS_raw_fastq}/termseq_expo_r2.fastq.gz',\n",
    "              f'{arnvig_TTS_raw_fastq}/termseq_expo_r3.fastq.gz']\n",
    "\n",
    "for fq in fastq_list:\n",
    "\n",
    "    command1 = f'fastqc {fq} -o {fastqc_dir} -t {threads}'\n",
    "\n",
    "    quickshell(\n",
    "            command1,\n",
    "            print_output = True,\n",
    "            return_output = False)\n",
    "\n",
    "    print(f'fastqc: {fq} done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea7080b",
   "metadata": {},
   "source": [
    "# Cortes: quality filter only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9bf75",
   "metadata": {},
   "source": [
    "fastqc showed no adapter contamination in Cortes, probably because the read length was shorter (50bp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "680b2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of reports for storage\n",
    "dataframe_list = []\n",
    "\n",
    "# trim adapters\n",
    "n_too_short = []\n",
    "\n",
    "# iterate through file pairs and trim adapters\n",
    "trimming_log = f'{cortes_TSS_processed_fastq}/split_trim_log.txt'\n",
    "\n",
    "sample_names = ['Exp_R1_TSS',\n",
    "                'Exp_R2_TSS',\n",
    "                'Exp_R3_TSS']\n",
    "\n",
    "with open(trimming_log, 'w') as f:\n",
    "    for sample_name in sample_names:\n",
    "        # prepare input and output titles\n",
    "        cutadapt_inputs = [\n",
    "            f'{cortes_TSS_raw_fastq}/{sample_name}.fastq.gz']\n",
    "        cutadapt_outputs = [\n",
    "             f'{cortes_TSS_processed_fastq}/{sample_name}.processed.fastq.gz']\n",
    "         # prepare cutadapt command\n",
    "        command = f'cutadapt --overlap=1 --minimum-length={minimum_insert_length} -q {quality_threshold} ' + \\\n",
    "                  f'-j {threads} -o {cutadapt_outputs[0]} ' + \\\n",
    "                  f'{cutadapt_inputs[0]}'\n",
    "        # run cutadapt\n",
    "        output_trim, _ = quickshell(command, print_output=True, return_output=True)\n",
    "        # parse output to pull number of reads below minimum_trimmed_length\n",
    "        too_short = int(regex.search('too short:\\s*\\S*',output_trim).group().split(' ')[-1].replace(',',''))\n",
    "        n_too_short.append(too_short)\n",
    "        # write full output to log\n",
    "        f.write(output_trim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c5879",
   "metadata": {},
   "source": [
    "# Arnvig TTS: quality filter and adapter trim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5ddbf",
   "metadata": {},
   "source": [
    "fastqc showed overrepresentation of Illumina Universal Adapter at 3' end, especially in replicate 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84d76a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of reports for storage\n",
    "dataframe_list = []\n",
    "\n",
    "# trim adapters\n",
    "n_too_short = []\n",
    "\n",
    "# iterate through file pairs and trim adapters\n",
    "trimming_log = f'{cortes_TSS_processed_fastq}/split_trim_log.txt'\n",
    "\n",
    "sample_names = ['termseq_expo_r1',\n",
    "                'termseq_expo_r2',\n",
    "                'termseq_expo_r3']\n",
    "\n",
    "universal_adapter = 'AGATCGGAAGAG'\n",
    "\n",
    "with open(trimming_log, 'w') as f:\n",
    "    for sample_name in sample_names:\n",
    "        # prepare input and output titles\n",
    "        cutadapt_inputs = [\n",
    "            f'{arnvig_TTS_raw_fastq}/{sample_name}.fastq.gz']\n",
    "        cutadapt_outputs = [\n",
    "             f'{arnvig_TTS_processed_fastq}/{sample_name}.processed.fastq.gz']\n",
    "         # prepare cutadapt command\n",
    "        command = f'cutadapt --overlap=1 --minimum-length={minimum_insert_length} -q {quality_threshold} ' + \\\n",
    "                  f'-j {threads} -a {universal_adapter} -o {cutadapt_outputs[0]} ' + \\\n",
    "                  f'{cutadapt_inputs[0]}'\n",
    "        # run cutadapt\n",
    "        output_trim, _ = quickshell(command, print_output=True, return_output=True)\n",
    "        # parse output to pull number of reads below minimum_trimmed_length\n",
    "        too_short = int(regex.search('too short:\\s*\\S*',output_trim).group().split(' ')[-1].replace(',',''))\n",
    "        n_too_short.append(too_short)\n",
    "        # write full output to log\n",
    "        f.write(output_trim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fce5df",
   "metadata": {},
   "source": [
    "## Pause here, change conda environment to ribodetector, and carry out ribodepletion in ribodetector Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6659d6",
   "metadata": {},
   "source": [
    "# Initial alignment to concatenated genome (Eco_Mtb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89df9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use BWA to align to concatenated genomes\n",
    "fastq_list = [f'{cortes_ribodetect}/Exp_R1_TSS_riboremove.fastq.gz',\n",
    "              f'{cortes_ribodetect}/Exp_R2_TSS_riboremove.fastq.gz',\n",
    "              f'{cortes_ribodetect}/Exp_R3_TSS_riboremove.fastq.gz',\n",
    "              f'{arnvig_ribodetect}/termseq_expo_r1_riboremove.fastq.gz',\n",
    "              f'{arnvig_ribodetect}/termseq_expo_r2_riboremove.fastq.gz',\n",
    "              f'{arnvig_ribodetect}/termseq_expo_r3_riboremove.fastq.gz']\n",
    "\n",
    "sample_names = ['Exp_R1_TSS', 'Exp_R2_TSS','Exp_R3_TSS',\n",
    "               'termseq_expo_r1', 'termseq_expo_r2', 'termseq_expo_r3']\n",
    "\n",
    "# bwa algorithm. Mem is default for most applications, read documentation to decide\n",
    "bwa_algorithm = 'mem'\n",
    "\n",
    "# Set print_output = True to see command-line output\n",
    "# Set return_output = False if assigning commmand-line output to a variable\n",
    "print_output = True\n",
    "return_output = False\n",
    "\n",
    "for i in range(len(fastq_list)):\n",
    "\n",
    "    map_command = f'bwa {bwa_algorithm} -t {threads} {genome_dir}/Eco_Mtb_genome.fasta ' + \\\n",
    "                       f'{fastq_list[i]} > {alignments}/{sample_names[i]}.sam'\n",
    "    \n",
    "    map = quickshell(map_command, print_output = print_output, return_output = return_output)\n",
    "    print(f'Initial alignment: {sample_names[i]} Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e61e0",
   "metadata": {},
   "source": [
    "# Sort and index bam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20288036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process alignments: \n",
    "# sort, convert to bam, and index\n",
    "sam_list = [f'{alignments}/Exp_R1_TSS.sam',\n",
    "            f'{alignments}/Exp_R2_TSS.sam',\n",
    "            f'{alignments}/Exp_R3_TSS.sam',\n",
    "            f'{alignments}/termseq_expo_r1.sam',\n",
    "            f'{alignments}/termseq_expo_r2.sam',\n",
    "            f'{alignments}/termseq_expo_r3.sam']\n",
    "\n",
    "\n",
    "sample_names = ['Exp_R1_TSS', 'Exp_R2_TSS','Exp_R3_TSS',\n",
    "               'termseq_expo_r1', 'termseq_expo_r2', 'termseq_expo_r3']\n",
    "\n",
    "# Set print_output = True to see command-line output\n",
    "# Set return_output = False if assigning commmand-line output to a variable\n",
    "print_output = True\n",
    "return_output = False\n",
    "\n",
    "for i in range(len(sam_list)):\n",
    "\n",
    "    # Sort sam file and output as bam\n",
    "    sort_enrich_command = f'samtools sort -O BAM {sam_list[i]} > ' + \\\n",
    "                          f'{alignments}/sorted_{sample_names[i]}.bam'\n",
    "\n",
    "    sort_enrich = quickshell(sort_enrich_command, print_output = print_output, return_output=return_output)\n",
    "    \n",
    "    # Index sorted bam\n",
    "    index_enrich_command = f'samtools index {alignments}/sorted_{sample_names[i]}.bam'\n",
    "    \n",
    "    index_enrich = quickshell(index_enrich_command, print_output = print_output, return_output=return_output)\n",
    "    print(f'Sort and index alignments: {sample_names[i]} done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e6235a",
   "metadata": {},
   "source": [
    "# Count number of non-rRNA reads mapping to the Mtb genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5' end samples\n",
    "sample_names = ['Exp_R1_TSS', 'Exp_R2_TSS','Exp_R3_TSS']\n",
    "\n",
    "bam_list = [f'{alignments}/sorted_Exp_R1_TSS.bam',\n",
    "            f'{alignments}/sorted_Exp_R2_TSS.bam',\n",
    "            f'{alignments}/sorted_Exp_R3_TSS.bam']\n",
    "\n",
    "# Exclude rRNA region\n",
    "Mtb_region1 = 'Eco_Mtb:4641653-6113234'\n",
    "Mtb_region2 = 'Eco_Mtb:6118672-9053361'\n",
    "\n",
    "# Whole genome\n",
    "Mtb_region = 'Eco_Mtb:4641653-9053361'\n",
    "\n",
    "read_counts = []\n",
    "\n",
    "for i in range(len(bam_list)):\n",
    "\n",
    "    count_reads_command = f'samtools view -c ' + \\\n",
    "                     f'{bam_list[i]} ' + \\\n",
    "                     f'\"{Mtb_region1}\" \"{Mtb_region2}\"'\n",
    "    count_reads = int(quickshell(count_reads_command,\n",
    "                                         print_output = True,\n",
    "                                         return_output= True)[0].split('\\n')[0])\n",
    "    read_counts.append([sample_names[i], count_reads])\n",
    "    \n",
    "    print(f'Counting reads: {sample_names[i]} done')\n",
    "    \n",
    "read_counts_DF = pd.DataFrame(read_counts, columns = ['Sample_Name','Read_Counts'])\n",
    "\n",
    "# Inspect read depths to decide on a minimum read depth to downsample all samples for subsequent analysis\n",
    "read_counts_DF.to_csv(f'{alignments}/inCellulo_5end_read_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc316c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3' end samples\n",
    "sample_names = ['termseq_expo_r1', 'termseq_expo_r2', 'termseq_expo_r3']\n",
    "\n",
    "bam_list = [f'{alignments}/sorted_termseq_expo_r1.bam',\n",
    "            f'{alignments}/sorted_termseq_expo_r2.bam',\n",
    "            f'{alignments}/sorted_termseq_expo_r3.bam']\n",
    "\n",
    "# Exclude rRNA region\n",
    "Mtb_region1 = 'Eco_Mtb:4641653-6113234'\n",
    "Mtb_region2 = 'Eco_Mtb:6118672-9053361'\n",
    "\n",
    "# Whole genome\n",
    "Mtb_region = 'Eco_Mtb:4641653-9053361'\n",
    "\n",
    "read_counts = []\n",
    "\n",
    "for i in range(len(bam_list)):\n",
    "\n",
    "    count_reads_command = f'samtools view -c ' + \\\n",
    "                     f'{bam_list[i]} ' + \\\n",
    "                     f'\"{Mtb_region1}\" \"{Mtb_region2}\"'\n",
    "    count_reads = int(quickshell(count_reads_command,\n",
    "                                         print_output = True,\n",
    "                                         return_output= True)[0].split('\\n')[0])\n",
    "    read_counts.append([sample_names[i], count_reads])\n",
    "    \n",
    "    print(f'Counting reads: {sample_names[i]} done')\n",
    "    \n",
    "read_counts_DF = pd.DataFrame(read_counts, columns = ['Sample_Name','Read_Counts'])\n",
    "\n",
    "# Inspect read depths to decide on a minimum read depth to downsample all samples for subsequent analysis\n",
    "read_counts_DF.to_csv(f'{alignments}/inCellulo_3end_read_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5942e",
   "metadata": {},
   "source": [
    "# Downsample cell-free samples (5' end and 3' end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "inCellulo_5end_read_counts = pd.read_csv(f'{alignments}/inCellulo_5end_read_counts.csv')\n",
    "\n",
    "CFG_5end_alignments = f'{CFG_5end_path}/readPrep/R2_alignments'\n",
    "original_CFG_5end_read_depths = pd.read_csv(f'{CFG_5end_alignments}/R2_read_counts.csv')\n",
    "\n",
    "# Here, after manual inspection,\n",
    "# the downsample depth is the minimum read depth across all samples. Can change if need be\n",
    "downsample_depth = inCellulo_5end_read_counts['Read_Counts'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample CFG 5' end RNA samples\n",
    "\n",
    "sample_names = ['noCRP1', 'noCRP2', 'noCRP3',\n",
    "               'CRP1', 'CRP2', 'CRP3']\n",
    "\n",
    "downsampled_depths = []\n",
    "\n",
    "for sample in sample_names:\n",
    "    \n",
    "    original_depth = original_CFG_5end_read_depths.loc[original_CFG_5end_read_depths['Sample_Name'] == sample,\n",
    "                                                       'R2_read_counts']\n",
    "    downsample_command = f'samtools view -b -s {(downsample_depth/int(original_depth))} ' + \\\n",
    "                         f'{CFG_5end_alignments}/{sample}_R2.bam > ' + \\\n",
    "                         f'{downsampled}/{sample}_downsample.bam'\n",
    "    downsample = quickshell(downsample_command,\n",
    "                            print_output = print_output,\n",
    "                            return_output = return_output)\n",
    "    \n",
    "    # Index the downsampled R2 only bam\n",
    "    index_downsample_command = f'samtools index {downsampled}/{sample}_downsample.bam'\n",
    "    index_downsample = quickshell(index_downsample_command,\n",
    "                                  print_output = print_output,\n",
    "                                  return_output = return_output)\n",
    "    \n",
    "    count_downsample_command = f'samtools view -c ' + \\\n",
    "                                  f'{downsampled}/{sample}_downsample.bam'\n",
    "    count_downsample = int(quickshell(count_downsample_command,\n",
    "                                         print_output = False,\n",
    "                                         return_output=True)[0].split('\\n')[0])\n",
    "    downsampled_depths.append([sample, count_downsample])\n",
    "    \n",
    "    print(f'Downsampling: {sample} done')\n",
    "    \n",
    "downsample_DF = pd.DataFrame(downsampled_depths, columns = ['Sample_Name','Downsampled_read_counts'])\n",
    "downsample_DF.to_csv(f'{downsampled}/downsampled_depths_CFG_5end.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72db3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample in cellulo 5' end RNA samples\n",
    "\n",
    "sample_names = ['Exp_R1_TSS', 'Exp_R2_TSS','Exp_R3_TSS']\n",
    "\n",
    "downsampled_depths = []\n",
    "\n",
    "for sample in sample_names:\n",
    "    \n",
    "    original_depth = inCellulo_5end_read_counts.loc[inCellulo_5end_read_counts['Sample_Name'] == sample,\n",
    "                                                       'Read_Counts']\n",
    "    downsample_command = f'samtools view -b -s {(downsample_depth/int(original_depth))} ' + \\\n",
    "                         f'{CFG_5end_alignments}/{sample}_R2.bam > ' + \\\n",
    "                         f'{downsampled}/{sample}_downsample.bam'\n",
    "    downsample = quickshell(downsample_command,\n",
    "                            print_output = print_output,\n",
    "                            return_output = return_output)\n",
    "    \n",
    "    # Index the downsampled R2 only bam\n",
    "    index_downsample_command = f'samtools index {downsampled}/{sample}_downsample.bam'\n",
    "    index_downsample = quickshell(index_downsample_command,\n",
    "                                  print_output = print_output,\n",
    "                                  return_output = return_output)\n",
    "    \n",
    "    count_downsample_command = f'samtools view -c ' + \\\n",
    "                                  f'{downsampled}/{sample}_downsample.bam'\n",
    "    count_downsample = int(quickshell(count_downsample_command,\n",
    "                                         print_output = False,\n",
    "                                         return_output=True)[0].split('\\n')[0])\n",
    "    downsampled_depths.append([sample, count_downsample])\n",
    "    \n",
    "    print(f'Downsampling: {sample} done')\n",
    "    \n",
    "downsample_DF = pd.DataFrame(downsampled_depths, columns = ['Sample_Name','Downsampled_read_counts'])\n",
    "downsample_DF.to_csv(f'{downsampled}/downsampled_depths_inCellulo_5end.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "inCellulo_3end_read_counts = pd.read_csv(f'{alignments}/inCellulo_3end_read_counts.csv')\n",
    "\n",
    "CFG_3end_alignments = f'{CFG_3end_path}/readPrep/R2_alignments'\n",
    "original_CFG_3end_read_depths = pd.read_csv(f'{CFG_3end_alignments}/R2_read_counts.csv')\n",
    "\n",
    "CFG_gDNA_alignments = 'gDNA/readPrep/R2_alignments'\n",
    "original_gDNA_read_depths = pd.read_csv(f'{CFG_gDNA_alignments}/R2_read_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d68bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample CFG 3' end RNA samples\n",
    "\n",
    "sample_names = ['noTF1', 'noTF2', 'noTF3',\n",
    "               'NusA1', 'NusA2', 'NusA3',\n",
    "               'NusG1', 'NusG2', 'NusG3',\n",
    "               'NusA_NusG1','NusA_NusG2','NusA_NusG3']\n",
    "\n",
    "downsampled_depths = []\n",
    "\n",
    "for sample in sample_names:\n",
    "    \n",
    "    original_depth = original_CFG_3end_read_depths.loc[original_CFG_3end_read_depths['Sample_Name'] == sample,\n",
    "                                                       'R2_read_counts']\n",
    "    downsample_command = f'samtools view -b -s {(downsample_depth/int(original_depth))} ' + \\\n",
    "                         f'{CFG_3end_alignments}/{sample}_R2.bam > ' + \\\n",
    "                         f'{downsampled}/{sample}_downsample.bam'\n",
    "    downsample = quickshell(downsample_command,\n",
    "                            print_output = print_output,\n",
    "                            return_output = return_output)\n",
    "    \n",
    "    # Index the downsampled R2 only bam\n",
    "    index_downsample_command = f'samtools index {downsampled}/{sample}_downsample.bam'\n",
    "    index_downsample = quickshell(index_downsample_command,\n",
    "                                  print_output = print_output,\n",
    "                                  return_output = return_output)\n",
    "    \n",
    "    count_downsample_command = f'samtools view -c ' + \\\n",
    "                                  f'{downsampled}/{sample}_downsample.bam'\n",
    "    count_downsample = int(quickshell(count_downsample_command,\n",
    "                                         print_output = False,\n",
    "                                         return_output=True)[0].split('\\n')[0])\n",
    "    downsampled_depths.append([sample, count_downsample])\n",
    "    \n",
    "    print(f'Downsampling: {sample} done')\n",
    "    \n",
    "downsample_DF = pd.DataFrame(downsampled_depths, columns = ['Sample_Name','Downsampled_read_counts'])\n",
    "downsample_DF.to_csv(f'{downsampled}/downsampled_depths_CFG_3end.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63646f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample CFG genomic DNA samples\n",
    "\n",
    "sample_names = ['gDNA1', 'gDNA2', 'gDNA3']\n",
    "\n",
    "downsampled_depths = []\n",
    "\n",
    "for sample in sample_names:\n",
    "    \n",
    "    original_depth = original_gDNA_read_depths.loc[original_gDNA_read_depths['Sample_Name'] == sample,\n",
    "                                                       'R2_read_counts']\n",
    "    downsample_command = f'samtools view -b -s {(downsample_depth/int(original_depth))} ' + \\\n",
    "                         f'{CFG_gDNA_alignments}/{sample}_R2.bam > ' + \\\n",
    "                         f'{downsampled}/{sample}_downsample.bam'\n",
    "    downsample = quickshell(downsample_command,\n",
    "                            print_output = print_output,\n",
    "                            return_output = return_output)\n",
    "    \n",
    "    # Index the downsampled R2 only bam\n",
    "    index_downsample_command = f'samtools index {downsampled}/{sample}_downsample.bam'\n",
    "    index_downsample = quickshell(index_downsample_command,\n",
    "                                  print_output = print_output,\n",
    "                                  return_output = return_output)\n",
    "    \n",
    "    count_downsample_command = f'samtools view -c ' + \\\n",
    "                                  f'{downsampled}/{sample}_downsample.bam'\n",
    "    count_downsample = int(quickshell(count_downsample_command,\n",
    "                                         print_output = False,\n",
    "                                         return_output=True)[0].split('\\n')[0])\n",
    "    downsampled_depths.append([sample, count_downsample])\n",
    "    \n",
    "    print(f'Downsampling: {sample} done')\n",
    "    \n",
    "downsample_DF = pd.DataFrame(downsampled_depths, columns = ['Sample_Name','Downsampled_read_counts'])\n",
    "downsample_DF.to_csv(f'{downsampled}/downsampled_depths_gDNA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a832832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample CFG 3' end RNA samples\n",
    "sample_names = ['termseq_expo_r1', 'termseq_expo_r2', 'termseq_expo_r3']\n",
    "\n",
    "downsampled_depths = []\n",
    "\n",
    "for sample in sample_names:\n",
    "    \n",
    "    original_depth = inCellulo_3end_read_counts.loc[inCellulo_3end_read_counts['Sample_Name'] == sample,\n",
    "                                                       'Read_Counts']\n",
    "    downsample_command = f'samtools view -b -s {(downsample_depth/int(original_depth))} ' + \\\n",
    "                         f'{CFG_3end_alignments}/{sample}_R2.bam > ' + \\\n",
    "                         f'{downsampled}/{sample}_downsample.bam'\n",
    "    downsample = quickshell(downsample_command,\n",
    "                            print_output = print_output,\n",
    "                            return_output = return_output)\n",
    "    \n",
    "    # Index the downsampled R2 only bam\n",
    "    index_downsample_command = f'samtools index {downsampled}/{sample}_downsample.bam'\n",
    "    index_downsample = quickshell(index_downsample_command,\n",
    "                                  print_output = print_output,\n",
    "                                  return_output = return_output)\n",
    "    \n",
    "    count_downsample_command = f'samtools view -c ' + \\\n",
    "                                  f'{downsampled}/{sample}_downsample.bam'\n",
    "    count_downsample = int(quickshell(count_downsample_command,\n",
    "                                         print_output = False,\n",
    "                                         return_output=True)[0].split('\\n')[0])\n",
    "    downsampled_depths.append([sample, count_downsample])\n",
    "    \n",
    "    print(f'Downsampling: {sample} done')\n",
    "    \n",
    "downsample_DF = pd.DataFrame(downsampled_depths, columns = ['Sample_Name','Downsampled_read_counts'])\n",
    "downsample_DF.to_csv(f'{downsampled}/downsampled_depths_inCellulo_3end.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ade86",
   "metadata": {},
   "source": [
    "# Trim all reads mapped to bam files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f4dcaa",
   "metadata": {},
   "source": [
    "Since minimum allowed read length during quality-processing was 10bp, trim all reads to 10bp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38a8bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = ['Exp_R1_TSS', 'Exp_R2_TSS','Exp_R3_TSS',\n",
    "                'noCRP1', 'noCRP2', 'noCRP3',\n",
    "               'CRP1', 'CRP2', 'CRP3',\n",
    "               'termseq_expo_r1', 'termseq_expo_r2', 'termseq_expo_r3',\n",
    "               'gDNA1', 'gDNA2', 'gDNA3',\n",
    "               'noTF1', 'noTF2', 'noTF3',\n",
    "               'NusA1', 'NusA2', 'NusA3',\n",
    "               'NusG1', 'NusG2', 'NusG3',\n",
    "               'NusA_NusG1','NusA_NusG2','NusA_NusG3']\n",
    "\n",
    "for sample in sample_names:\n",
    "    trim_command = f'reformat.sh in={downsampled}/{sample}_downsample.bam out={trimmed}/{sample}_trimmed.bam ' + \\\n",
    "                    f' allowidenticalnames=t overwrite=true forcetrimright=10'\n",
    "    trim_read_lengths = quickshell(trim_command,\n",
    "                                   print_output = True,\n",
    "                                   return_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d47cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether read lengths are actually 10 using:\n",
    "# samtools view bamname.bam | awk '{print length($10)}' | head -1000 | sort -u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abb2f8",
   "metadata": {},
   "source": [
    "# Sort and index new trimmed .bam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc1eeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = ['Exp_R1_TSS', 'Exp_R2_TSS','Exp_R3_TSS',\n",
    "                'noCRP1', 'noCRP2', 'noCRP3',\n",
    "               'CRP1', 'CRP2', 'CRP3',\n",
    "               'termseq_expo_r1', 'termseq_expo_r2', 'termseq_expo_r3',\n",
    "               'gDNA1', 'gDNA2', 'gDNA3',\n",
    "               'noTF1', 'noTF2', 'noTF3',\n",
    "               'NusA1', 'NusA2', 'NusA3',\n",
    "               'NusG1', 'NusG2', 'NusG3',\n",
    "               'NusA_NusG1','NusA_NusG2','NusA_NusG3']\n",
    "\n",
    "print_output = True\n",
    "return_output = False\n",
    "\n",
    "for sample in sample_names:\n",
    "\n",
    "    # Sort sam file and output as bam\n",
    "    sort_command = f'samtools sort -O BAM {trimmed}/{sample}_trimmed.bam > ' + \\\n",
    "                          f'{trimmed}/sorted_{sample}_trimmed.bam'\n",
    "\n",
    "    sort = quickshell(sort_command, print_output = print_output, return_output = return_output)\n",
    "    \n",
    "    # Index sorted bam\n",
    "    index_command = f'samtools index {trimmed}/sorted_{sample}_trimmed.bam'\n",
    "    \n",
    "    index = quickshell(index_command, print_output = print_output, return_output=return_output)\n",
    "    print(f'Sort and index alignments: {sample} done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c0ef3",
   "metadata": {},
   "source": [
    "# Count number of reads mapping to each genomic region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48fed50",
   "metadata": {},
   "source": [
    "Genomic region = genes and intergenic regions, both strands.\n",
    "Need to generate a list of trimmed bam files here as a .txt file as input for summarizeOverlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55960bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizeOverlaps_command = f'Rscript --vanilla Rscripts/CFG_summarizeOverlaps.R ' + \\\n",
    "            f'-b {summarizeOverlaps}/BamList.txt ' + \\\n",
    "            f'-g geneModel_genomicRegions.csv ' + \\\n",
    "            f'-o {summarizeOverlaps}/downsampled_trimmed_genomicRegions.csv'\n",
    "quickshell(summarizeOverlaps_5end_command, print_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44778239",
   "metadata": {},
   "source": [
    "# Visualize coverage differences between in cellulo vs. cell-free transcription (Fig. 2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63093516",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_dir = 'fig2_inCellulo_vs_CFG/fig2C_coverage_violinBoxPlots'\n",
    "\n",
    "summarizeOverlaps_5end_command = f'Rscript --vanilla {figure_dir}/fig2C_inCellulo_vs_CFG_coverage.R ' + \\\n",
    "            f'-g geneModel_genomicRegions.csv ' + \\\n",
    "            f'-s {summarizeOverlaps}/downsampled_trimmed_genomicRegions.csv ' + \\\n",
    "            f'-f {figure_dir}/log2_5end_coverage.png ' + \\\n",
    "            f'-e {figure_dir}/log2_3end_coverage.png'\n",
    "quickshell(summarizeOverlaps_5end_command, print_output = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
