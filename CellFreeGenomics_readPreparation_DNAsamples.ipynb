{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "266b1e95",
   "metadata": {},
   "source": [
    "# Cell-Free Genomics: FASTQ preparation and alignment for genomic DNA samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e943305e",
   "metadata": {},
   "source": [
    "#### Ruby Froom, Campbell/Darst and Rock labs at Rockefeller University\n",
    "\n",
    "The following pipeline processes raw FASTQ files, maps reads, and extracts R2 reads for the relevant genome from genomic DNA samples, to serve as a 'blacklist' sample for TTS calling from RNA 3' end datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08aac1",
   "metadata": {},
   "source": [
    "## Modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c972395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "import pysam\n",
    "import csv\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from os.path import exists\n",
    "from Bio import SeqRecord\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f6dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# written by Peter Culviner, PhD to enable command-line access through Jupyter\n",
    "def quickshell(command, print_output=True, output_path=None, return_output=False):\n",
    "    process_output = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout = process_output.stdout.decode('utf-8')\n",
    "    stderr = process_output.stderr.decode('utf-8')\n",
    "    output_string = f'STDOUT:\\n{stdout}\\nSTDERR:\\n{stderr}\\n'\n",
    "    if print_output:\n",
    "        print('$ ' + command)\n",
    "        print(output_string)\n",
    "    if output_path is not None:\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(output_string)\n",
    "    if return_output:\n",
    "        return stdout, stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a6d32",
   "metadata": {},
   "source": [
    "## Initializing inputs and settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713ddb9",
   "metadata": {},
   "source": [
    "Inputs for directory creation and pointing to files. \n",
    "\n",
    "The starting requirements for this pipeline are:\n",
    ">**main_path**: the absolute path of the working directory. Update to reflect your own configuration.\n",
    "\n",
    ">**input_csv_dir:** a directory containing `i7_sample_file` csv called `input_csv_files`.\n",
    ">>**i7_sample_file**: Used to identify fastq files to split from. Assumes we're working with fastqs that have already been split by Illumina's i7 indexes. Minimally should have columns:\n",
    ">>>**r1**: read 1 fastq, no inline barcode, template starts from first base.\n",
    "\n",
    ">>>**r2**: read 2 fastq, this one is assumed to have the inline barcode starting from the first base.\n",
    "\n",
    ">>>**i7**: number to designate this fastq, used internally by the code and used to designate in which unsplit fastq files final samples exist. minimally, each fastq pair should have a unique number.\n",
    "\n",
    ">>>**title**: used internally for pool names during splitting, unique but the name itself is not important.\n",
    "\n",
    "\n",
    ">**genome_dir:** a directory containing reference genome(s) for read mapping. Here, called `genome_files_misc`.\n",
    "\n",
    ">**raw_fastq_dir:** a sub-directory containing your i7-demultiplexed fastq files. Here, called `raw_fastq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2b3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing locations of input .csv files, alignment genomes and raw compressed fastq files\n",
    "main_path = 'gDNA'\n",
    "input_csv_dir = f'{main_path}/input_csv_files'\n",
    "readPrep_dir = f'{main_path}/readPrep'\n",
    "genome_dir = 'genome_files_misc'\n",
    "raw_fastq_dir = f'{readPrep_dir}/raw_fastq'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b219c5",
   "metadata": {},
   "source": [
    "The additional directories below are a suggested organization for subsequent processing steps in this notebook.\n",
    "\n",
    "The cells below will initialize these variables and create the directories inside the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09f6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqc_dir = f'{readPrep_dir}/fastqc'\n",
    "\n",
    "# Directory for fastqs quality filtered and Illumina adaptors trimmed\n",
    "trimmed_fastq_dir = f'{readPrep_dir}/trimmed_fastq'\n",
    "\n",
    "alignments_dir = f'{readPrep_dir}/alignments'\n",
    "R2_alignments_dir = f'{readPrep_dir}/R2_alignments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e517ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories if needed\n",
    "!mkdir $fastqc_dir\n",
    "\n",
    "!mkdir $trimmed_fastq_dir\n",
    "\n",
    "!mkdir $alignments_dir\n",
    "!mkdir $R2_alignments_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0effe907",
   "metadata": {},
   "source": [
    "*Descriptions written by Peter Culviner, PhD with modifications from Ruby Froom.*\n",
    "\n",
    "**threads:** number of threads to use in command-line calls (e.g. fastqc, cutadapt, bwa, end calling).\n",
    "\n",
    "**inline_barcode_errors:** How many mismatches can be tolerated in the inline barcode. Analyze the edit distance between the barcodes used to assess a tolerable number of errors.\n",
    "\n",
    "**barcode_length**: the length of the inline barcodes. Enables calculation of the error rate (# errors / barcode length), a required input for `cutadapt` when we are splitting based on inline barcode identification.\n",
    "\n",
    "**minimum_insert_length:** minimum allowed length of insert after trimming of adapter sequences at the 3'-ends of read1 and read2.\n",
    "\n",
    "**i7_trim**: For 3'-end trimming of the first read. The adapter sequence to look for at the 3'-end of the read. Note that the reverse complement of the inline barcode for a given sample will be appended to the front of this string since the inline barcode would appear just before this string.\n",
    "\n",
    "**i5_trim**: For 3'-end trimming of the second read. The adapter sequence to look for at the 3'-end of the read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec0d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "\n",
    "# Threads (CPU x2 is max) for fastqc, cutadapt, bwa, and end calling\n",
    "threads = 22\n",
    "\n",
    "# Quality filters\n",
    "minimum_insert_length = 10\n",
    "quality_threshold = 20\n",
    "\n",
    "# 3'-adapter trimming\n",
    "i7_trim = 'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'\n",
    "i5_trim = 'GATCGTCGGACTGTAGAACTCTGAACGTGTAGATCTCGGTGGTCGCCGTATCATT'\n",
    "\n",
    "i7_table = pd.read_csv(f'{input_csv_dir}/i7_barcodes_gDNA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeddf29f",
   "metadata": {},
   "source": [
    "## Generate quality reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d431a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in i7_table.iterrows():\n",
    "    _, i7_data = row\n",
    "    R1 = i7_data.r1\n",
    "    R2 = i7_data.r2\n",
    "\n",
    "    command1 = f'fastqc {raw_fastq_dir}/{R1} -o {fastqc_dir} -t {threads}'\n",
    "    command2 = f'fastqc {raw_fastq_dir}/{R2} -o {fastqc_dir} -t {threads}'\n",
    "\n",
    "    quickshell(\n",
    "            command1,\n",
    "            print_output=False,\n",
    "            return_output=False)\n",
    "\n",
    "    print(f'R1 fastqc: {i7_data.title} done')\n",
    "\n",
    "    quickshell(\n",
    "            command2,\n",
    "            print_output=False,\n",
    "            return_output=False)\n",
    "    \n",
    "    print(f'R2 fastqc: {i7_data.title} done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6e9f6",
   "metadata": {},
   "source": [
    "## Quality-filter reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b87e28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through file pairs and trim adapters\n",
    "trimming_log = f'{trimmed_fastq_dir}/gDNA_split_trim_log.txt'\n",
    "with open(trimming_log, 'w') as f:\n",
    "    for row in i7_table.iterrows():\n",
    "        _, sample_data = row\n",
    "        # prepare input and output titles\n",
    "        cutadapt_inputs = [\n",
    "            f'{raw_fastq_dir}/{sample_data.r1}',\n",
    "            f'{raw_fastq_dir}/{sample_data.r2}']\n",
    "        cutadapt_outputs = [\n",
    "            f'{trimmed_fastq_dir}/{sample_data.title}.R1.fastq.gz',\n",
    "            f'{trimmed_fastq_dir}/{sample_data.title}.R2.fastq.gz']\n",
    "        # prepare cutadapt command\n",
    "        # read from read 1\n",
    "        i7_adapter = f'{i7_trim}'\n",
    "        # read from read 2\n",
    "        i5_adapter = f'{i5_trim}'\n",
    "        command = f'cutadapt --overlap=1 --minimum-length={minimum_insert_length} -q {quality_threshold} ' + \\\n",
    "                  f'-j {threads} -a {i7_adapter} -A {i5_adapter} -o {cutadapt_outputs[0]} ' + \\\n",
    "                  f'-p {cutadapt_outputs[1]} {cutadapt_inputs[0]} {cutadapt_inputs[1]}'\n",
    "        # run cutadapt\n",
    "        output_trim, _ = quickshell(command, print_output=False, return_output=True)\n",
    "        # write full output to log\n",
    "        f.write(output_trim + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa4763b",
   "metadata": {},
   "source": [
    "# Mapping reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013501d",
   "metadata": {},
   "source": [
    "Map the reads to 2 concatenated genomes: a spike genome (Eco) and an experimental genome of interest (Mtb).\n",
    "\n",
    "To enable spike-based absolute quantification across conditions, I map to a concatenated genome where Mtb comes first, then Eco, so that ambiguously-mapping reads are removed from the spike quantitation.\n",
    "\n",
    "For the end enrichment calling, the same logic applies, but now the Eco genome comes first to remove ambiguously-mapping reads from the final end enrichment quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a95d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the input genomes (only needs to be done once)\n",
    "index_genome_command = f'bwa index {genome_dir}/Eco_Mtb_genome.fasta'\n",
    "\n",
    "index_genome = quickshell(index_genome_command, print_output = True, return_output = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49050856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use BWA to align to concatenated genomes \n",
    "# for spike calculation and subsequent end enrichment analysis\n",
    "\n",
    "# bwa algorithm. Mem is default for most applications, read documentation to decide\n",
    "bwa_algorithm = 'mem'\n",
    "\n",
    "# Set print_output = True to see command-line output\n",
    "# Set return_output = True if assigning commmand-line output to a variable\n",
    "print_output = True\n",
    "return_output = False\n",
    "\n",
    "for row in i7_table.iterrows():\n",
    "    _, sample_data = row\n",
    "    R1_reads = f'{trimmed_fastq_dir}/{sample_data.title}.R1.fastq.gz'\n",
    "    R2_reads = f'{trimmed_fastq_dir}/{sample_data.title}.R2.fastq.gz'\n",
    "\n",
    "    map_command = f'bwa {bwa_algorithm} -t {threads} {genome_dir}/Eco_Mtb_genome.fasta ' + \\\n",
    "                       f'{R1_reads} {R2_reads} > {alignments_dir}/{sample_data.title}.sam'\n",
    "    \n",
    "    map_output = quickshell(map_command, print_output = print_output, return_output = return_output)\n",
    "    print(f'Initial alignments: {sample_data.title} Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ae74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process alignments: \n",
    "# sort, convert to bam, and index\n",
    "\n",
    "# Set print_output = True to see command-line output\n",
    "# Set return_output = True if assigning commmand-line output to a variable\n",
    "print_output = False\n",
    "return_output = False\n",
    "\n",
    "for row in i7_table.iterrows():\n",
    "    _, sample_data = row\n",
    "    # Sort sam file and output as bam\n",
    "    sort_command = f'samtools sort -O BAM {alignments_dir}/{sample_data.title}.sam > ' + \\\n",
    "                          f'{alignments_dir}/sorted_{sample_data.title}.bam'\n",
    "    \n",
    "    sort_output = quickshell(sort_command, print_output = print_output, return_output=return_output)\n",
    "    \n",
    "    # Index sorted bam\n",
    "    index_command = f'samtools index {alignments_dir}/sorted_{sample_data.title}.bam'\n",
    "    \n",
    "    index_output = quickshell(index_command, print_output = print_output, return_output = return_output)\n",
    "\n",
    "    print(f'Sort and index alignments before de-duplication: {sample_data.title} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87157b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mapping statistics\n",
    "\n",
    "# List to generate dataframe with spike counts for normalization (needed in downstream analysis)\n",
    "# and other mapping statistics (not needed)\n",
    "mapping_stats = []\n",
    "\n",
    "# Update with the name of your genome and relevant regions\n",
    "Eco_region = 'Eco_Mtb:1-4641652'\n",
    "Mtb_region = 'Eco_Mtb:4641653-9053361'\n",
    "\n",
    "for row in i7_table.iterrows():\n",
    "    _, sample_data = row\n",
    "    # Extract mapping stats\n",
    "    count_Mtb_reads_command = f'samtools view -c -F 260 ' + \\\n",
    "                              f'{alignments_dir}/sorted_{sample_data.title}.bam \"{Mtb_region}\"'\n",
    "    count_Mtb_reads = int(quickshell(count_Mtb_reads_command,\n",
    "                                     print_output = False,\n",
    "                                     return_output=True)[0].split('\\n')[0])\n",
    "    \n",
    "    count_all_mapped_reads_command = f'samtools view -c -F 260 ' + \\\n",
    "                                         f'{alignments_dir}/sorted_{sample_data.title}.bam'\n",
    "    count_all_mapped_reads = int(quickshell(count_all_mapped_reads_command,\n",
    "                                                print_output = False,\n",
    "                                                return_output=True)[0].split('\\n')[0])\n",
    "    Mtb_percent = (count_Mtb_reads / count_all_mapped_reads) * 100\n",
    "    \n",
    "    count_Eco_reads_command = f'samtools view -c -F 260 ' + \\\n",
    "                                f'{alignments_dir}/sorted_{sample_data.title}.bam \"{Eco_region}\"'\n",
    "    count_Eco_reads = int(quickshell(count_Eco_reads_command,\n",
    "                                       print_output = False,\n",
    "                                       return_output=True)[0].split('\\n')[0])\n",
    "\n",
    "    Eco_percent = (count_Eco_reads / count_all_mapped_reads) * 100\n",
    "    \n",
    "    count_unmapped_reads_command = f'samtools view -c -f 4 ' + \\\n",
    "                                       f'{alignments_dir}/sorted_{sample_data.title}.bam'\n",
    "    count_unmapped_reads = int(quickshell(count_unmapped_reads_command,\n",
    "                                              print_output = False,\n",
    "                                              return_output=True)[0].split('\\n')[0])\n",
    "    \n",
    "    \n",
    "    count_all_reads_command = f'samtools view -c ' + \\\n",
    "                                  f'{alignments_dir}/sorted_{sample_data.title}.bam'\n",
    "    count_all_reads = int(quickshell(count_all_reads_command,\n",
    "                                         print_output = False,\n",
    "                                         return_output=True)[0].split('\\n')[0])\n",
    "    unmapped_percent = (count_unmapped_reads / count_all_reads) * 100\n",
    "    \n",
    "    mapping_stats.append([sample_data.title, count_Eco_reads, Eco_percent, count_Mtb_reads,\n",
    "                          Mtb_percent, unmapped_percent])\n",
    "    \n",
    "    print(f'Mapping stats: {sample_data.title} done')\n",
    "\n",
    "mapping_DF = pd.DataFrame(mapping_stats, columns = ['Sample_Name','Eco Counts',\n",
    "                                                    'Eco % Mapped','Mtb Counts','Mtb % Mapped',\n",
    "                                                    '% Unmapped'])\n",
    "mapping_DF.to_csv(f'{alignments_dir}/mapping_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e0a08",
   "metadata": {},
   "source": [
    "# Extract only Mtb R2 reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e0b8e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set print_output = True to see command-line output\n",
    "# Set return_output = False if assigning commmand-line output to a variable\n",
    "print_output = False\n",
    "return_output = False\n",
    "\n",
    "Mtb_region = 'Eco_Mtb:4641653-9053361'\n",
    "\n",
    "for row in i7_table.iterrows():\n",
    "    _, sample_data = row\n",
    "    # Output the R2 reads mapping to the genome with enriched ends to analyze  \n",
    "    ref_R2_command = f'samtools view -b -f 0x0080 ' + \\\n",
    "                     f'{alignments_dir}/sorted_{sample_data.title}.bam ' + \\\n",
    "                     f'\"{Mtb_region}\" -o {R2_alignments_dir}/{sample_data.title}_R2.bam'\n",
    "    ref_R2 = quickshell(ref_R2_command, print_output = print_output, return_output = return_output)\n",
    "    \n",
    "    # Index the R2 only bam\n",
    "    index_R2_command = f'samtools index {R2_alignments_dir}/{sample_data.title}_R2.bam'\n",
    "    index_R2 = quickshell(index_R2_command, print_output = print_output, return_output = return_output)\n",
    "    print(f'Generate and index R2-only alignments: {sample_data.title} done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
